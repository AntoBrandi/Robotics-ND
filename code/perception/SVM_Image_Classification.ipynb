{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classification using SVM\n",
    "With the SVM algorithm categorize images whether or not they are cars\n",
    "\n",
    "![title](svm_class.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Load the images from a pre-defined dataset in which are already splitted the image with a car from those whithout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car Images: 1196\n",
      "Non-Car Images: 1125\n"
     ]
    }
   ],
   "source": [
    "# Read in car and non-car images\n",
    "cars = glob.glob('./vehicles/cars*/*.jpeg')\n",
    "notcars = glob.glob('./non-vehicles/notcars*/*.jpeg')\n",
    "\n",
    "print('Car Images: {}'.format(len(cars)))\n",
    "print('Non-Car Images: {}'.format(len(notcars)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features\n",
    "Extract a Color histogram for each picture\n",
    "\n",
    "* Convert the Image from RGB to HSV\n",
    "* Extract a color Histogram for each color channel\n",
    "* Combine the Histogram of the differents color channels\n",
    "* Normalize the Histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute color histogram features  \n",
    "def color_hist(img_rgb, nbins=32, bins_range=(0, 256)):\n",
    "    # Convert from RGB to HSV using cv2.cvtColor()\n",
    "    img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    ### Take histograms in three channels\n",
    "    ch_1 = np.histogram(img_hsv[:,:,0], bins=nbins, range=bins_range)\n",
    "    ch_2 = np.histogram(img_hsv[:,:,1], bins=nbins, range=bins_range)\n",
    "    ch_3 = np.histogram(img_hsv[:,:,2], bins=nbins, range=bins_range)\n",
    "                        \n",
    "    ### Concatenate the histograms into a single feature vector\n",
    "    # Generating bin centers\n",
    "    bin_edges = ch_1[1]\n",
    "    bin_centers = (bin_edges[1:]  + bin_edges[0:len(bin_edges)-1])/2\n",
    "                        \n",
    "    # Normalize the result\n",
    "    hist_features = np.concatenate((ch_1[0], ch_2[0], ch_3[0])).astype(np.float64)\n",
    "    norm_features = hist_features / np.sum(hist_features)\n",
    "    \n",
    "    # Return the feature vector\n",
    "    return norm_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract features from a list of images\n",
    "# Have this function call color_hist()\n",
    "def extract_features(imgs, hist_bins=32, hist_range=(0, 256)):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # Apply color_hist() \n",
    "        hist_features = color_hist(image, nbins=hist_bins, bins_range=hist_range)\n",
    "        # Append the new feature vector to the features list\n",
    "        features.append(hist_features)\n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters of the SVM and Test Train Set\n",
    "Shuffle the images in order to avoid undesiderable strange behaviours due to some randomy contiguous images and split the dataset of images into a train and test set.\n",
    "\n",
    "The Train set will then be used to train the model and the test set will be used to test and validate the model on some unknown new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset includes 1196 cars and 1125 not-cars\n",
      "Using 12 histogram bins\n",
      "Feature vector length: 36\n"
     ]
    }
   ],
   "source": [
    "# performs under different binning scenarios\n",
    "histbin = 32\n",
    "\n",
    "car_features = extract_features(cars, hist_bins=histbin, hist_range=(0, 256))\n",
    "notcar_features = extract_features(notcars, hist_bins=histbin, hist_range=(0, 256))\n",
    "\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "\n",
    "# Shuffle the images\n",
    "rand_state = np.random.randint(0, 100)\n",
    "# Split up data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Dataset includes', len(cars), 'cars and', len(notcars), 'not-cars')\n",
    "print('Using', histbin,'histogram bins')\n",
    "print('Feature vector length:', len(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the SVM Model\n",
    "Using the Test set extracted in the step above, train an SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03 Seconds to train SVC...\n"
     ]
    }
   ],
   "source": [
    "# Use a linear SVC \n",
    "svc = SVC(kernel='rbf')\n",
    "\n",
    "# Check the training time for the SVC\n",
    "t = time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model\n",
    "Comparing the prediction of the model on the Test set with the correct values, evaluates the score of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of SVC =  0.9978\n",
      "My SVC predicts:  [1. 0. 1. 0. 0. 0. 1. 1. 0. 1.]\n",
      "For these 10 labels:  [1. 0. 1. 0. 0. 0. 1. 1. 0. 1.]\n",
      "0.00299 Seconds to predict 10 labels with SVC\n"
     ]
    }
   ],
   "source": [
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
